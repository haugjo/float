<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>float.concept_drift_detection.erics API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>float.concept_drift_detection.erics</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import numpy as np
from scipy.stats import norm
from warnings import warn
import copy
from float.concept_drift_detection.concept_drift_detector import ConceptDriftDetector


class ERICS(ConceptDriftDetector):
    &#34;&#34;&#34;
    ERICS: Effective and Robust Identification of Concept Shift
    please cite:
    [1] Haug, Johannes and Kasneci, Gjergji. &#34;Learning Parameter Distributions to Detect Concept Drift in Data Streams&#34;.
    CoRR. 2020.
    [2] Haug, Johannes, et al. &#34;Leveraging Model Inherent Variable Importance for Stable Online Feature Selection&#34;.
    Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. 2020.
    &#34;&#34;&#34;
    def __init__(self, n_param, evaluation_metrics=None, window_mvg_average=50, window_drift_detect=50, beta=0.0001, base_model=&#39;probit&#39;,
                 init_mu=0, init_sigma=1, epochs=10, lr_mu=0.01, lr_sigma=0.01):
        &#34;&#34;&#34;

        Args:
            n_param (int): total no. of parameters (corresponds to no. of features for probit model)
            evaluation_metrics (dict of str: function | dict of str: (function, dict)): {metric_name: metric_function} OR {metric_name: (metric_function, {param_name1: param_val1, ...})} a dictionary of metrics to be used
            window_mvg_average (int): window Size for computation of moving average
            window_drift_detect (int): window Size for Drift Detection
            beta (float): update rate for the alpha-threshold
            base_model (str): name of the base predictive model (whose parameters we investigate)
            init_mu (int): initialize mean of parameter distributions (according to [2])
            init_sigma (int): initialize variance of parameter distributions (according to [2])
            epochs (int): number of epochs for optimization of parameter distributions (according to [2])
            lr_mu (float): learning rate for the gradient update of the mean (according to [2])
            lr_sigma (float): learning rate for the gradient update of the variance (according to [2])
        &#34;&#34;&#34;
        super().__init__(evaluation_metrics)
        # User-set ERICS-hyperparameters
        self.n_param = n_param
        self.M = window_mvg_average
        self.W = window_drift_detect
        self.beta = beta
        self.base_model = base_model

        # Default hyperparameters
        self.time_step = 0                                           # Current Time Step
        self.time_since_last_global_drift = 0                        # Time steps since last global drift detection
        self.time_since_last_partial_drift = np.zeros(n_param)       # Time steps since last partial drift detection
        self.alpha = None                                            # Adaptive threshold for global concept drift detection
        self.partial_alpha = np.asarray([None] * self.n_param)       # Adaptive threshold for partial concept drift detection
        self.mu_w = np.ones((self.M, self.n_param)) * init_mu        # Parameter Mean in window
        self.sigma_w = np.ones((self.M, self.n_param)) * init_sigma  # Parameter Variance in window
        self.param_sum = np.zeros((self.M - 1, self.n_param))        # Sum-expression for computation of moving average (see Eq. (8) in [1])
        self.global_info_ma = []                                     # Global moving average
        self.partial_info_ma = []                                    # Partial moving average

        # Parameters of FIRES (Probit) model according to [2]
        if self.base_model == &#39;probit&#39;:
            self.fires_mu = np.ones(self.n_param) * init_mu
            self.fires_sigma = np.ones(self.n_param) * init_sigma
            self.fires_epochs = epochs
            self.fires_lr_mu = lr_mu
            self.fires_lr_sigma = lr_sigma
            self.fires_labels = []                                          # Unique labels (fires requires binary labels)
            self.fires_encode_labels = True                                 # Indicator for warning message (auto-encoded labels)

        self.global_drift_detected = False
        self.partial_drift_detected = False

        self.partial_drifts = []

        self.prediction_based = False

        # ### ADD YOUR OWN MODEL PARAMETERS HERE ############################
        # if self.base_model == &#39;your_model&#39;:
        #   # define parameters
        #####################################################################

    def reset(self):
        pass

    def partial_fit(self, X, y):
        &#34;&#34;&#34;
        Process data batch and check for concept drift.

        Args:
            X (np.ndarray): Batch of observations
            y (np.ndarray): Batch of labels

        Returns:
            (bool, bool, float): indicator global drift, indicator partial drift, computation time in sec.
        &#34;&#34;&#34;
        self.global_drift_detected = False
        self.global_drift_detected = False

        # Update alpha (Eq. 7 in [1])
        if self.alpha is not None:
            self.alpha -= (self.alpha * self.beta * self.time_since_last_global_drift)
        for k in range(self.n_param):  # partial alpha
            if self.partial_alpha[k] is not None:
                self.partial_alpha[k] -= (self.partial_alpha[k] * self.beta * self.time_since_last_partial_drift[k])

        # Update time since drift
        self.time_since_last_global_drift += 1
        self.time_since_last_partial_drift += 1

        # Update Parameter distribution
        if self.base_model == &#39;probit&#39;:
            self.__update_probit(X, y)  # Probit model
        # ### ADD YOUR OWN MODEL HERE #######################################
        # elif(self.base_model == &#39;your_model&#39;:
        #   self.__update_your_model(x,y)
        #####################################################################
        else:
            raise NotImplementedError(&#39;The base model {} has not been implemented.&#39;.format(self.base_model))

        self.__update_param_sum()                   # Update the sum expression for observations in a shifting window
        self.__compute_moving_average()             # Compute moving average in specified window
        self.global_drift_detected, self.partial_drift_detected = self.__detect_drift()    # Detect concept drift

        # Update time step
        self.time_step += 1

    def __update_param_sum(self):
        &#34;&#34;&#34;
        Retrieve current parameter distribution and compute sum expression according to Eq. (8) in the ERICS paper [1]
        &#34;&#34;&#34;
        # Retrieve current distribution parameters
        if self.base_model == &#39;probit&#39;:
            new_mu = copy.copy(self.fires_mu).reshape(1, -1)
            new_sigma = copy.copy(self.fires_sigma).reshape(1, -1)
        # ### ADD YOUR OWN MODEL HERE #######################################
        # elif(self.base_model == &#39;your_model&#39;:
        #   new_mu = your_model.mu
        #   new_sigma = your_model.sigma
        #####################################################################
        else:
            raise NotImplementedError(&#39;The base model {} has not been implemented.&#39;.format(self.base_model))

        # Drop oldest entry from window
        self.mu_w = self.mu_w[1:, :]
        self.sigma_w = self.sigma_w[1:, :]

        # Add new entry to window
        self.mu_w = np.concatenate((self.mu_w, new_mu))
        self.sigma_w = np.concatenate((self.sigma_w, new_sigma))

        # Compute parameter sum expression
        for t in range(self.M - 1):
            self.param_sum[t, :] = (self.sigma_w[t + 1, :] ** 2 + (self.mu_w[t, :] - self.mu_w[t + 1, :]) ** 2) / self.sigma_w[t, :] ** 2

    def __compute_moving_average(self):
        &#34;&#34;&#34;
        Compute the moving average (according to Eq. (8) in the ERICS paper [1])
        &#34;&#34;&#34;
        partial_ma = np.zeros(self.n_param)
        global_score = np.zeros(self.M - 1)

        for k in range(self.n_param):
            partial_score = self.param_sum[:, k] - 1
            global_score += partial_score
            partial_ma[k] = np.sum(np.abs(partial_score)) / (2 * self.M)  # Add partial mov. avg. for parameter k

        global_ma = np.sum(np.abs(global_score)) / (2 * self.M)

        self.global_info_ma.append(global_ma)
        self.partial_info_ma.append(partial_ma)

    def __detect_drift(self):
        &#34;&#34;&#34;
        Detect global and partial concept drift using the adaptive alpha-threshold
        :return: global drift indicator, partial drift indicator
        :rtype: bool, bool
        &#34;&#34;&#34;
        global_window_delta = None
        partial_window_delta = None

        # Compute delta in sliding window W (according to Eq. (5) in the ERICS paper [1])
        if self.W &lt; 2:
            self.W = 2
            warn(&#39;Sliding window for concept drift detection was automatically set to 2 observations.&#39;)

        if len(self.global_info_ma) &lt; self.W:
            oldest_entry = len(self.global_info_ma)
        else:
            oldest_entry = self.W

        if oldest_entry == 1:  # In case of only one observation
            global_window_delta = copy.copy(self.global_info_ma[-1])
            partial_window_delta = copy.copy(self.partial_info_ma[-1])
        else:
            for t in range(oldest_entry, 1, -1):
                if t == oldest_entry:
                    global_window_delta = self.global_info_ma[-t+1] - self.global_info_ma[-t]  # newer - older
                    partial_window_delta = self.partial_info_ma[-t+1] - self.partial_info_ma[-t]
                else:
                    global_window_delta += (self.global_info_ma[-t+1] - self.global_info_ma[-t])
                    partial_window_delta += (self.partial_info_ma[-t+1] - self.partial_info_ma[-t])

        # (Re-) Initialize alpha if it is None (at time step 0 or if a drift was detected)
        if self.alpha is None:
            self.alpha = np.abs(global_window_delta)  # according to Eq. (6) in [1] -&gt; abs() is only required at t=0, to make sure that alpha &gt; 0
        if None in self.partial_alpha:
            unspecified = np.isnan(self.partial_alpha.astype(float)).flatten()
            self.partial_alpha[unspecified] = np.abs(partial_window_delta[unspecified])

        # Global Drift Detection
        g_drift = False
        if global_window_delta &gt; self.alpha:
            g_drift = True
            self.time_since_last_global_drift = 0
            self.alpha = None

        # Partial Drift Detection
        p_drift = False
        partial_drift_bool = partial_window_delta &gt; self.partial_alpha
        for k in np.argwhere(partial_drift_bool):
            p_drift = True
            self.time_since_last_partial_drift[k] = 0
            self.partial_alpha[k] = None

        return g_drift, p_drift

    ###########################################
    # BASE MODELS
    ##########################################
    def __update_probit(self, x, y):
        &#34;&#34;&#34;
        Update parameters of the Probit model
        According to [2], as implemented here https://github.com/haugjo/fires
        We have slightly adjusted the original code to fit our use case.
        :param x: (np.ndarray) Batch of observations (numeric values only, consider normalizing data for better results)
        :param y: (np.ndarray) Batch of labels: type binary, i.e. {-1,1} (bool, int or str will be encoded accordingly)
        &#34;&#34;&#34;
        # Encode labels
        for y_val in np.unique(y):  # Add newly observed unique labels
            if y_val not in set(self.fires_labels):
                self.fires_labels.append(y_val)

        if tuple(self.fires_labels) != (-1, 1):  # Check if labels are encoded correctly
            if self.fires_encode_labels:
                warn(&#39;FIRES WARNING: The target variable will automatically be encoded as {-1, 1}.&#39;)
                self.fires_encode_labels = False  # set indicator to false

            if len(self.fires_labels) &lt; 2:
                y[y == self.fires_labels[0]] = -1
            elif len(self.fires_labels) == 2:
                y[y == self.fires_labels[0]] = -1
                y[y == self.fires_labels[1]] = 1
            else:
                raise ValueError(&#39;The target variable y must be binary.&#39;)

        for epoch in range(self.fires_epochs):
            # Shuffle the observations
            random_idx = np.random.permutation(len(y))
            x = x[random_idx]
            y = y[random_idx]

            # Iterative update of mu and sigma
            try:
                # Helper functions
                dot_mu_x = np.dot(x, self.fires_mu)
                rho = np.sqrt(1 + np.dot(x ** 2, self.fires_sigma ** 2))

                # Gradients
                nabla_mu = norm.pdf(y / rho * dot_mu_x) * (y / rho * x.T)
                nabla_sigma = norm.pdf(y / rho * dot_mu_x) * (
                            - y / (2 * rho ** 3) * 2 * (x ** 2 * self.fires_sigma).T * dot_mu_x)

                # Marginal Likelihood
                marginal = norm.cdf(y / rho * dot_mu_x)

                # Update parameters
                self.fires_mu += self.fires_lr_mu * np.mean(nabla_mu / marginal, axis=1)
                self.fires_sigma += self.fires_lr_sigma * np.mean(nabla_sigma / marginal, axis=1)
            except TypeError as e:
                raise TypeError(&#39;All features must be a numeric data type.&#39;) from e

    def detected_global_change(self):
        return self.global_drift_detected

    def detected_partial_change(self):
        return self.partial_drift_detected

    def detected_warning_zone(self):
        pass

    def get_length_estimation(self):
        pass

    # ### ADD YOUR OWN MODEL HERE #######################################
    # def __update_your_model(x,y):
    #   # update the parameters of your model
    #####################################################################

    def evaluate(self, time_step, last_iteration):
        &#34;&#34;&#34;
        Evaluates the concept drift detector at one time step.

        Args:
            time_step (int): the current time step
            last_iteration (bool): True if this is the last iteration of the pipeline, False otherwise
        &#34;&#34;&#34;
        super().evaluate(time_step, last_iteration)

        if self.detected_partial_change():
            if time_step not in self.partial_drifts:
                self.partial_drifts.append(time_step)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="float.concept_drift_detection.erics.ERICS"><code class="flex name class">
<span>class <span class="ident">ERICS</span></span>
<span>(</span><span>n_param, evaluation_metrics=None, window_mvg_average=50, window_drift_detect=50, beta=0.0001, base_model='probit', init_mu=0, init_sigma=1, epochs=10, lr_mu=0.01, lr_sigma=0.01)</span>
</code></dt>
<dd>
<div class="desc"><p>ERICS: Effective and Robust Identification of Concept Shift
please cite:
[1] Haug, Johannes and Kasneci, Gjergji. "Learning Parameter Distributions to Detect Concept Drift in Data Streams".
CoRR. 2020.
[2] Haug, Johannes, et al. "Leveraging Model Inherent Variable Importance for Stable Online Feature Selection".
Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. 2020.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n_param</code></strong> :&ensp;<code>int</code></dt>
<dd>total no. of parameters (corresponds to no. of features for probit model)</dd>
<dt>evaluation_metrics (dict of str: function | dict of str: (function, dict)): {metric_name: metric_function} OR {metric_name: (metric_function, {param_name1: param_val1, &hellip;})} a dictionary of metrics to be used</dt>
<dt><strong><code>window_mvg_average</code></strong> :&ensp;<code>int</code></dt>
<dd>window Size for computation of moving average</dd>
<dt><strong><code>window_drift_detect</code></strong> :&ensp;<code>int</code></dt>
<dd>window Size for Drift Detection</dd>
<dt><strong><code>beta</code></strong> :&ensp;<code><a title="float" href="../index.html">float</a></code></dt>
<dd>update rate for the alpha-threshold</dd>
<dt><strong><code>base_model</code></strong> :&ensp;<code>str</code></dt>
<dd>name of the base predictive model (whose parameters we investigate)</dd>
<dt><strong><code>init_mu</code></strong> :&ensp;<code>int</code></dt>
<dd>initialize mean of parameter distributions (according to [2])</dd>
<dt><strong><code>init_sigma</code></strong> :&ensp;<code>int</code></dt>
<dd>initialize variance of parameter distributions (according to [2])</dd>
<dt><strong><code>epochs</code></strong> :&ensp;<code>int</code></dt>
<dd>number of epochs for optimization of parameter distributions (according to [2])</dd>
<dt><strong><code>lr_mu</code></strong> :&ensp;<code><a title="float" href="../index.html">float</a></code></dt>
<dd>learning rate for the gradient update of the mean (according to [2])</dd>
<dt><strong><code>lr_sigma</code></strong> :&ensp;<code><a title="float" href="../index.html">float</a></code></dt>
<dd>learning rate for the gradient update of the variance (according to [2])</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ERICS(ConceptDriftDetector):
    &#34;&#34;&#34;
    ERICS: Effective and Robust Identification of Concept Shift
    please cite:
    [1] Haug, Johannes and Kasneci, Gjergji. &#34;Learning Parameter Distributions to Detect Concept Drift in Data Streams&#34;.
    CoRR. 2020.
    [2] Haug, Johannes, et al. &#34;Leveraging Model Inherent Variable Importance for Stable Online Feature Selection&#34;.
    Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. 2020.
    &#34;&#34;&#34;
    def __init__(self, n_param, evaluation_metrics=None, window_mvg_average=50, window_drift_detect=50, beta=0.0001, base_model=&#39;probit&#39;,
                 init_mu=0, init_sigma=1, epochs=10, lr_mu=0.01, lr_sigma=0.01):
        &#34;&#34;&#34;

        Args:
            n_param (int): total no. of parameters (corresponds to no. of features for probit model)
            evaluation_metrics (dict of str: function | dict of str: (function, dict)): {metric_name: metric_function} OR {metric_name: (metric_function, {param_name1: param_val1, ...})} a dictionary of metrics to be used
            window_mvg_average (int): window Size for computation of moving average
            window_drift_detect (int): window Size for Drift Detection
            beta (float): update rate for the alpha-threshold
            base_model (str): name of the base predictive model (whose parameters we investigate)
            init_mu (int): initialize mean of parameter distributions (according to [2])
            init_sigma (int): initialize variance of parameter distributions (according to [2])
            epochs (int): number of epochs for optimization of parameter distributions (according to [2])
            lr_mu (float): learning rate for the gradient update of the mean (according to [2])
            lr_sigma (float): learning rate for the gradient update of the variance (according to [2])
        &#34;&#34;&#34;
        super().__init__(evaluation_metrics)
        # User-set ERICS-hyperparameters
        self.n_param = n_param
        self.M = window_mvg_average
        self.W = window_drift_detect
        self.beta = beta
        self.base_model = base_model

        # Default hyperparameters
        self.time_step = 0                                           # Current Time Step
        self.time_since_last_global_drift = 0                        # Time steps since last global drift detection
        self.time_since_last_partial_drift = np.zeros(n_param)       # Time steps since last partial drift detection
        self.alpha = None                                            # Adaptive threshold for global concept drift detection
        self.partial_alpha = np.asarray([None] * self.n_param)       # Adaptive threshold for partial concept drift detection
        self.mu_w = np.ones((self.M, self.n_param)) * init_mu        # Parameter Mean in window
        self.sigma_w = np.ones((self.M, self.n_param)) * init_sigma  # Parameter Variance in window
        self.param_sum = np.zeros((self.M - 1, self.n_param))        # Sum-expression for computation of moving average (see Eq. (8) in [1])
        self.global_info_ma = []                                     # Global moving average
        self.partial_info_ma = []                                    # Partial moving average

        # Parameters of FIRES (Probit) model according to [2]
        if self.base_model == &#39;probit&#39;:
            self.fires_mu = np.ones(self.n_param) * init_mu
            self.fires_sigma = np.ones(self.n_param) * init_sigma
            self.fires_epochs = epochs
            self.fires_lr_mu = lr_mu
            self.fires_lr_sigma = lr_sigma
            self.fires_labels = []                                          # Unique labels (fires requires binary labels)
            self.fires_encode_labels = True                                 # Indicator for warning message (auto-encoded labels)

        self.global_drift_detected = False
        self.partial_drift_detected = False

        self.partial_drifts = []

        self.prediction_based = False

        # ### ADD YOUR OWN MODEL PARAMETERS HERE ############################
        # if self.base_model == &#39;your_model&#39;:
        #   # define parameters
        #####################################################################

    def reset(self):
        pass

    def partial_fit(self, X, y):
        &#34;&#34;&#34;
        Process data batch and check for concept drift.

        Args:
            X (np.ndarray): Batch of observations
            y (np.ndarray): Batch of labels

        Returns:
            (bool, bool, float): indicator global drift, indicator partial drift, computation time in sec.
        &#34;&#34;&#34;
        self.global_drift_detected = False
        self.global_drift_detected = False

        # Update alpha (Eq. 7 in [1])
        if self.alpha is not None:
            self.alpha -= (self.alpha * self.beta * self.time_since_last_global_drift)
        for k in range(self.n_param):  # partial alpha
            if self.partial_alpha[k] is not None:
                self.partial_alpha[k] -= (self.partial_alpha[k] * self.beta * self.time_since_last_partial_drift[k])

        # Update time since drift
        self.time_since_last_global_drift += 1
        self.time_since_last_partial_drift += 1

        # Update Parameter distribution
        if self.base_model == &#39;probit&#39;:
            self.__update_probit(X, y)  # Probit model
        # ### ADD YOUR OWN MODEL HERE #######################################
        # elif(self.base_model == &#39;your_model&#39;:
        #   self.__update_your_model(x,y)
        #####################################################################
        else:
            raise NotImplementedError(&#39;The base model {} has not been implemented.&#39;.format(self.base_model))

        self.__update_param_sum()                   # Update the sum expression for observations in a shifting window
        self.__compute_moving_average()             # Compute moving average in specified window
        self.global_drift_detected, self.partial_drift_detected = self.__detect_drift()    # Detect concept drift

        # Update time step
        self.time_step += 1

    def __update_param_sum(self):
        &#34;&#34;&#34;
        Retrieve current parameter distribution and compute sum expression according to Eq. (8) in the ERICS paper [1]
        &#34;&#34;&#34;
        # Retrieve current distribution parameters
        if self.base_model == &#39;probit&#39;:
            new_mu = copy.copy(self.fires_mu).reshape(1, -1)
            new_sigma = copy.copy(self.fires_sigma).reshape(1, -1)
        # ### ADD YOUR OWN MODEL HERE #######################################
        # elif(self.base_model == &#39;your_model&#39;:
        #   new_mu = your_model.mu
        #   new_sigma = your_model.sigma
        #####################################################################
        else:
            raise NotImplementedError(&#39;The base model {} has not been implemented.&#39;.format(self.base_model))

        # Drop oldest entry from window
        self.mu_w = self.mu_w[1:, :]
        self.sigma_w = self.sigma_w[1:, :]

        # Add new entry to window
        self.mu_w = np.concatenate((self.mu_w, new_mu))
        self.sigma_w = np.concatenate((self.sigma_w, new_sigma))

        # Compute parameter sum expression
        for t in range(self.M - 1):
            self.param_sum[t, :] = (self.sigma_w[t + 1, :] ** 2 + (self.mu_w[t, :] - self.mu_w[t + 1, :]) ** 2) / self.sigma_w[t, :] ** 2

    def __compute_moving_average(self):
        &#34;&#34;&#34;
        Compute the moving average (according to Eq. (8) in the ERICS paper [1])
        &#34;&#34;&#34;
        partial_ma = np.zeros(self.n_param)
        global_score = np.zeros(self.M - 1)

        for k in range(self.n_param):
            partial_score = self.param_sum[:, k] - 1
            global_score += partial_score
            partial_ma[k] = np.sum(np.abs(partial_score)) / (2 * self.M)  # Add partial mov. avg. for parameter k

        global_ma = np.sum(np.abs(global_score)) / (2 * self.M)

        self.global_info_ma.append(global_ma)
        self.partial_info_ma.append(partial_ma)

    def __detect_drift(self):
        &#34;&#34;&#34;
        Detect global and partial concept drift using the adaptive alpha-threshold
        :return: global drift indicator, partial drift indicator
        :rtype: bool, bool
        &#34;&#34;&#34;
        global_window_delta = None
        partial_window_delta = None

        # Compute delta in sliding window W (according to Eq. (5) in the ERICS paper [1])
        if self.W &lt; 2:
            self.W = 2
            warn(&#39;Sliding window for concept drift detection was automatically set to 2 observations.&#39;)

        if len(self.global_info_ma) &lt; self.W:
            oldest_entry = len(self.global_info_ma)
        else:
            oldest_entry = self.W

        if oldest_entry == 1:  # In case of only one observation
            global_window_delta = copy.copy(self.global_info_ma[-1])
            partial_window_delta = copy.copy(self.partial_info_ma[-1])
        else:
            for t in range(oldest_entry, 1, -1):
                if t == oldest_entry:
                    global_window_delta = self.global_info_ma[-t+1] - self.global_info_ma[-t]  # newer - older
                    partial_window_delta = self.partial_info_ma[-t+1] - self.partial_info_ma[-t]
                else:
                    global_window_delta += (self.global_info_ma[-t+1] - self.global_info_ma[-t])
                    partial_window_delta += (self.partial_info_ma[-t+1] - self.partial_info_ma[-t])

        # (Re-) Initialize alpha if it is None (at time step 0 or if a drift was detected)
        if self.alpha is None:
            self.alpha = np.abs(global_window_delta)  # according to Eq. (6) in [1] -&gt; abs() is only required at t=0, to make sure that alpha &gt; 0
        if None in self.partial_alpha:
            unspecified = np.isnan(self.partial_alpha.astype(float)).flatten()
            self.partial_alpha[unspecified] = np.abs(partial_window_delta[unspecified])

        # Global Drift Detection
        g_drift = False
        if global_window_delta &gt; self.alpha:
            g_drift = True
            self.time_since_last_global_drift = 0
            self.alpha = None

        # Partial Drift Detection
        p_drift = False
        partial_drift_bool = partial_window_delta &gt; self.partial_alpha
        for k in np.argwhere(partial_drift_bool):
            p_drift = True
            self.time_since_last_partial_drift[k] = 0
            self.partial_alpha[k] = None

        return g_drift, p_drift

    ###########################################
    # BASE MODELS
    ##########################################
    def __update_probit(self, x, y):
        &#34;&#34;&#34;
        Update parameters of the Probit model
        According to [2], as implemented here https://github.com/haugjo/fires
        We have slightly adjusted the original code to fit our use case.
        :param x: (np.ndarray) Batch of observations (numeric values only, consider normalizing data for better results)
        :param y: (np.ndarray) Batch of labels: type binary, i.e. {-1,1} (bool, int or str will be encoded accordingly)
        &#34;&#34;&#34;
        # Encode labels
        for y_val in np.unique(y):  # Add newly observed unique labels
            if y_val not in set(self.fires_labels):
                self.fires_labels.append(y_val)

        if tuple(self.fires_labels) != (-1, 1):  # Check if labels are encoded correctly
            if self.fires_encode_labels:
                warn(&#39;FIRES WARNING: The target variable will automatically be encoded as {-1, 1}.&#39;)
                self.fires_encode_labels = False  # set indicator to false

            if len(self.fires_labels) &lt; 2:
                y[y == self.fires_labels[0]] = -1
            elif len(self.fires_labels) == 2:
                y[y == self.fires_labels[0]] = -1
                y[y == self.fires_labels[1]] = 1
            else:
                raise ValueError(&#39;The target variable y must be binary.&#39;)

        for epoch in range(self.fires_epochs):
            # Shuffle the observations
            random_idx = np.random.permutation(len(y))
            x = x[random_idx]
            y = y[random_idx]

            # Iterative update of mu and sigma
            try:
                # Helper functions
                dot_mu_x = np.dot(x, self.fires_mu)
                rho = np.sqrt(1 + np.dot(x ** 2, self.fires_sigma ** 2))

                # Gradients
                nabla_mu = norm.pdf(y / rho * dot_mu_x) * (y / rho * x.T)
                nabla_sigma = norm.pdf(y / rho * dot_mu_x) * (
                            - y / (2 * rho ** 3) * 2 * (x ** 2 * self.fires_sigma).T * dot_mu_x)

                # Marginal Likelihood
                marginal = norm.cdf(y / rho * dot_mu_x)

                # Update parameters
                self.fires_mu += self.fires_lr_mu * np.mean(nabla_mu / marginal, axis=1)
                self.fires_sigma += self.fires_lr_sigma * np.mean(nabla_sigma / marginal, axis=1)
            except TypeError as e:
                raise TypeError(&#39;All features must be a numeric data type.&#39;) from e

    def detected_global_change(self):
        return self.global_drift_detected

    def detected_partial_change(self):
        return self.partial_drift_detected

    def detected_warning_zone(self):
        pass

    def get_length_estimation(self):
        pass

    # ### ADD YOUR OWN MODEL HERE #######################################
    # def __update_your_model(x,y):
    #   # update the parameters of your model
    #####################################################################

    def evaluate(self, time_step, last_iteration):
        &#34;&#34;&#34;
        Evaluates the concept drift detector at one time step.

        Args:
            time_step (int): the current time step
            last_iteration (bool): True if this is the last iteration of the pipeline, False otherwise
        &#34;&#34;&#34;
        super().evaluate(time_step, last_iteration)

        if self.detected_partial_change():
            if time_step not in self.partial_drifts:
                self.partial_drifts.append(time_step)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector">ConceptDriftDetector</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="float.concept_drift_detection.erics.ERICS.partial_fit"><code class="name flex">
<span>def <span class="ident">partial_fit</span></span>(<span>self, X, y)</span>
</code></dt>
<dd>
<div class="desc"><p>Process data batch and check for concept drift.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Batch of observations</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Batch of labels</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>(bool, bool, float): indicator global drift, indicator partial drift, computation time in sec.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def partial_fit(self, X, y):
    &#34;&#34;&#34;
    Process data batch and check for concept drift.

    Args:
        X (np.ndarray): Batch of observations
        y (np.ndarray): Batch of labels

    Returns:
        (bool, bool, float): indicator global drift, indicator partial drift, computation time in sec.
    &#34;&#34;&#34;
    self.global_drift_detected = False
    self.global_drift_detected = False

    # Update alpha (Eq. 7 in [1])
    if self.alpha is not None:
        self.alpha -= (self.alpha * self.beta * self.time_since_last_global_drift)
    for k in range(self.n_param):  # partial alpha
        if self.partial_alpha[k] is not None:
            self.partial_alpha[k] -= (self.partial_alpha[k] * self.beta * self.time_since_last_partial_drift[k])

    # Update time since drift
    self.time_since_last_global_drift += 1
    self.time_since_last_partial_drift += 1

    # Update Parameter distribution
    if self.base_model == &#39;probit&#39;:
        self.__update_probit(X, y)  # Probit model
    # ### ADD YOUR OWN MODEL HERE #######################################
    # elif(self.base_model == &#39;your_model&#39;:
    #   self.__update_your_model(x,y)
    #####################################################################
    else:
        raise NotImplementedError(&#39;The base model {} has not been implemented.&#39;.format(self.base_model))

    self.__update_param_sum()                   # Update the sum expression for observations in a shifting window
    self.__compute_moving_average()             # Compute moving average in specified window
    self.global_drift_detected, self.partial_drift_detected = self.__detect_drift()    # Detect concept drift

    # Update time step
    self.time_step += 1</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector">ConceptDriftDetector</a></b></code>:
<ul class="hlist">
<li><code><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.detected_global_change" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.detected_global_change">detected_global_change</a></code></li>
<li><code><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.detected_partial_change" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.detected_partial_change">detected_partial_change</a></code></li>
<li><code><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.detected_warning_zone" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.detected_warning_zone">detected_warning_zone</a></code></li>
<li><code><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.evaluate" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.evaluate">evaluate</a></code></li>
<li><code><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.get_average_delay" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.get_average_delay">get_average_delay</a></code></li>
<li><code><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.get_fdr" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.get_fdr">get_fdr</a></code></li>
<li><code><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.get_length_estimation" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.get_length_estimation">get_length_estimation</a></code></li>
<li><code><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.get_precision" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.get_precision">get_precision</a></code></li>
<li><code><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.get_tpr" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.get_tpr">get_tpr</a></code></li>
<li><code><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.get_tpr_fdr_and_precision" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.get_tpr_fdr_and_precision">get_tpr_fdr_and_precision</a></code></li>
<li><code><a title="float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.reset" href="concept_drift_detector.html#float.concept_drift_detection.concept_drift_detector.ConceptDriftDetector.reset">reset</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="float.concept_drift_detection" href="index.html">float.concept_drift_detection</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="float.concept_drift_detection.erics.ERICS" href="#float.concept_drift_detection.erics.ERICS">ERICS</a></code></h4>
<ul class="">
<li><code><a title="float.concept_drift_detection.erics.ERICS.partial_fit" href="#float.concept_drift_detection.erics.ERICS.partial_fit">partial_fit</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>