{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99027cdd-96c7-459c-a960-55da5fb64012",
   "metadata": {},
   "source": [
    "# Experiment: Holdout Pipeline - Online Classification\n",
    "\n",
    "In this exemplary experiment we use float to compare three online classifiers with respect to different performance measures. We use a holdout evaluation strategy.\n",
    "\n",
    "The holdout pipeline can be used similarly to the prequential pipeline. Hence, **for more detailed information, e.g. regarding feature selection, concept drift detection, or additional visualization options, please see one of the experiments for the prequential pipeline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c134c5b7-d029-4317-976f-dca39ad4a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Rebase the file path.\n",
    "# Note that you may also provide explicit file paths and avoid this step.\n",
    "import os\n",
    "os.chdir(os.getcwd()[:-18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed864e2-ffc2-4b08-9c49-c413be41b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skmultiflow.trees import HoeffdingTreeClassifier, HoeffdingAdaptiveTreeClassifier\n",
    "from river.linear_model import Perceptron, LogisticRegression\n",
    "\n",
    "# Import float modules\n",
    "from float.data import DataLoader\n",
    "from float.data.preprocessing import SklearnScaler\n",
    "from float.pipeline import HoldoutPipeline\n",
    "from float.prediction.skmultiflow import SkmultiflowClassifier\n",
    "from float.prediction.river import RiverClassifier\n",
    "from float.prediction.evaluation import PredictionEvaluator\n",
    "from float.prediction.evaluation.measures import noise_variability\n",
    "import float.visualization as fvis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a644f25b-bb7a-4a92-943b-e674e1cee8fc",
   "metadata": {},
   "source": [
    "### Setup *float* modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a9c4bf-dd27-4d82-ae3a-5d387cca2d5b",
   "metadata": {},
   "source": [
    "#### Create a DataLoader object\n",
    "We load the Electricity data set (https://www.openml.org/d/151) and specify an sklearn MinMaxScaler for the normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e954689-201a-455e-89f6-b76d92728a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(path='float/data/datasets/electricity.csv',  # This path might have to be adjusted!\n",
    "                         target_col=-1,\n",
    "                         scaler=SklearnScaler(MinMaxScaler())\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf30da-a7b0-4150-92ff-33b523691ad5",
   "metadata": {},
   "source": [
    "#### Create Predictor objects\n",
    "We setup a list of predictors. Specifically, we want to compare models from skmultiflow and river. We use the default parameters of the packages, however, in general you can provide any configuration you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8738515e-64b4-44d3-888f-be7745603821",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [SkmultiflowClassifier(model=HoeffdingAdaptiveTreeClassifier(), classes=data_loader.stream.target_values),\n",
    "              SkmultiflowClassifier(model=HoeffdingTreeClassifier(), classes=data_loader.stream.target_values),\n",
    "              RiverClassifier(model=LogisticRegression(), feature_names=data_loader.stream.feature_names)\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00da7482-e0b3-4661-8cba-38bed8d193d7",
   "metadata": {},
   "source": [
    "#### Create a PredictorEvaluator object.\n",
    "The evaluator will compute and store the performance measures when running the pipeline. Float automatically clones the provided evaluator for each specified predictor object.\n",
    "\n",
    "We specify a decay rate, i.e. the evaluator will additionally store aggregated measures with an exponential decay.\n",
    "\n",
    "Note that you can hand any parameter of a measure function directly to the Evaluator, e.g. below we specify the zero_division parameter of the precision_score and the reference_measure and n_samples parameters of the noise_variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29df9d6c-290b-4e66-abc4-b21e01b5567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = PredictionEvaluator(measure_funcs=[accuracy_score, precision_score, noise_variability],\n",
    "                                decay_rate=0.1,\n",
    "                                zero_division=0,\n",
    "                                reference_measure=accuracy_score,\n",
    "                                n_samples=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d08bfd-74c0-4484-b1df-5245514ff2bf",
   "metadata": {},
   "source": [
    "#### Create and run a HoldoutPipeline\n",
    "\n",
    "We use a batch-incremental scheme, processing the data in batches of size 10. Moreover, we pretrain the classifiers on 200 observations and set a random state for reproducibility.\n",
    "\n",
    "For the holdout evaluation, we need to provide a **test_set**. If we do not provide a test set ourselves, the HoldoutPipeline will automatically use the first batch as test set.\n",
    "\n",
    "The **test_interval** specifies the frequency in which we perform tests using the holdout set. Here, we specify that we want to test the models at every 100th time step.\n",
    "\n",
    "The **test_replace_interval** allows us to update the test set over time. In particular, we want to use every x'th observation to replace the oldest instance in the test set. Below, we tell the pipeline to use every 50th new observation for testing. In this way, we can maintain a representative holdout set over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd5131f5-bd19-445d-a39f-6e4cf7b9d543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain the predictor with 200 observation(s).\n",
      "\n",
      "################################## SUMMARY ##################################\n",
      "Evaluation has finished after 0.48031020164489746s\n",
      "Data Set: float/data/datasets/electricity.csv\n",
      "The HoldoutPipeline has processed 200 instances, using batches of size 10.\n",
      "-------------------------------------------------------------------------\n",
      "*** Prediction ***\n",
      "Model: SkmultiflowClassifier.HoeffdingAdaptiveTreeClassifier\n",
      "| Performance Measure    |       Value |\n",
      "|------------------------|-------------|\n",
      "| Avg. Test Comp. Time   |  0.013962   |\n",
      "| Avg. Train Comp. Time  |  0.00997305 |\n",
      "| Avg. accuracy_score    |  0.66       |\n",
      "| Avg. precision_score   |  0.66       |\n",
      "| Avg. noise_variability | -0.0366667  |\n",
      "Model: SkmultiflowClassifier.HoeffdingTreeClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Johannes Haug\\Documents\\float\\float\\pipeline\\holdout_pipeline.py\", line 170, in run\n",
      "    self._run_iteration(train_set=train_set,\n",
      "  File \"C:\\Users\\Johannes Haug\\Documents\\float\\float\\pipeline\\base_pipeline.py\", line 303, in _run_iteration\n",
      "    prediction_evaluator.run(y_true=copy.copy(y_test),\n",
      "  File \"C:\\Users\\Johannes Haug\\Documents\\float\\float\\prediction\\evaluation\\prediction_evaluator.py\", line 135, in run\n",
      "    new_measure_val = measure_func(**call_args)\n",
      "  File \"C:\\Users\\Johannes Haug\\Documents\\float\\float\\prediction\\evaluation\\measures\\noise_variability.py\", line 86, in noise_variability\n",
      "    old_score = reference_measure(**call_args)\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 205, in accuracy_score\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 85, in _check_targets\n",
      "    type_true = type_of_target(y_true)\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 328, in type_of_target\n",
      "    if (len(np.unique(y)) > 2) or (y.ndim >= 2 and len(y[0]) > 1):\n",
      "  File \"<__array_function__ internals>\", line 5, in unique\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 262, in unique\n",
      "    ret = _unique1d(ar, return_index, return_inverse, return_counts)\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 323, in _unique1d\n",
      "    ar.sort()\n",
      "KeyboardInterrupt\n",
      "C:\\Users\\Johannes Haug\\Documents\\float\\float\\pipeline\\utils_pipeline.py:207: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(prediction_evaluator.training_comp_times)]]  # Aggregate data\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\JOHANN~1\\AppData\\Local\\Temp/ipykernel_14392/2835285978.py\", line 15, in <module>\n",
      "    pipeline.run()\n",
      "  File \"C:\\Users\\Johannes Haug\\Documents\\float\\float\\pipeline\\holdout_pipeline.py\", line 181, in run\n",
      "    self._finish_evaluation()\n",
      "  File \"C:\\Users\\Johannes Haug\\Documents\\float\\float\\pipeline\\base_pipeline.py\", line 451, in _finish_evaluation\n",
      "    print_evaluation_summary(pipeline=self)\n",
      "  File \"C:\\Users\\Johannes Haug\\Documents\\float\\float\\pipeline\\utils_pipeline.py\", line 208, in print_evaluation_summary\n",
      "    tab_data.extend([['Avg. {}'.format(key), value['mean'][-1]]\n",
      "  File \"C:\\Users\\Johannes Haug\\Documents\\float\\float\\pipeline\\utils_pipeline.py\", line 208, in <listcomp>\n",
      "    tab_data.extend([['Avg. {}'.format(key), value['mean'][-1]]\n",
      "IndexError: list index out of range\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'IndexError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\Johannes Haug\\miniconda3\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\JOHANN~1\\AppData\\Local\\Temp/ipykernel_14392/2835285978.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                            random_state=0)\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\float\\float\\pipeline\\holdout_pipeline.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_finish_evaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\float\\float\\pipeline\\base_pipeline.py\u001b[0m in \u001b[0;36m_finish_evaluation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[0mprint_evaluation_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\float\\float\\pipeline\\utils_pipeline.py\u001b[0m in \u001b[0;36mprint_evaluation_summary\u001b[1;34m(pipeline)\u001b[0m\n\u001b[0;32m    207\u001b[0m                              np.nanmean(prediction_evaluator.training_comp_times)]]  # Aggregate data\n\u001b[1;32m--> 208\u001b[1;33m                 tab_data.extend([['Avg. {}'.format(key), value['mean'][-1]]\n\u001b[0m\u001b[0;32m    209\u001b[0m                                  for key, value in prediction_evaluator.result.items()])\n",
      "\u001b[1;32m~\\Documents\\float\\float\\pipeline\\utils_pipeline.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    207\u001b[0m                              np.nanmean(prediction_evaluator.training_comp_times)]]  # Aggregate data\n\u001b[1;32m--> 208\u001b[1;33m                 tab_data.extend([['Avg. {}'.format(key), value['mean'][-1]]\n\u001b[0m\u001b[0;32m    209\u001b[0m                                  for key, value in prediction_evaluator.result.items()])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2063\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'IndexError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# We sample a holdout set and reset the data stream afterwards.\n",
    "holdout_set = data_loader.get_data(100)\n",
    "data_loader.stream.reset()\n",
    "\n",
    "pipeline = HoldoutPipeline(data_loader=data_loader,\n",
    "                           predictor=predictors,\n",
    "                           prediction_evaluator=evaluator,\n",
    "                           batch_size=10,\n",
    "                           n_pretrain=200,\n",
    "                           n_max=data_loader.stream.n_samples,  # We use all observations\n",
    "                           test_set=holdout_set,\n",
    "                           test_interval=100,\n",
    "                           test_replace_interval = 50,\n",
    "                           random_state=0)\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c3e960-1f7b-4215-aa03-7311aaa6ba32",
   "metadata": {},
   "source": [
    "The summarized results suggest that the Hoeffding Tree based classifiers are superior to the logistic regression model. We may get further insight into the performance of the classifiers by using the visualization module of float."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb9898-6b77-4207-9b2e-8b183c5fe405",
   "metadata": {},
   "source": [
    "### Visualizing Results\n",
    "\n",
    "Float provides standardized plot types that may be used to illustrate results stored in an evaluator object. \n",
    "However, note that you can essentially do whatever you like with the evaluator object, e.g. save it or create custom tables.\n",
    "\n",
    "The evaluator object contains all results, e.g. performance measures and computation times, that were calculated during the pipeline run. Since we trained 3 predictors, the pipeline.prediction_evaluators object contains 3 evaluators.\n",
    "\n",
    "We begin by illustrating the raw accuracy measures of each classifier using a regular line plot. Note that the HoldoutPipeline has only tested the models every 100th time step. That is, at all remaining time steps, the PredictionEvaluator has saved 'nan'. To plot the results of the holdout evaluation, we want to ignore these nan measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85254ef-d23b-4629-92c2-f6e9ac6870c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = []\n",
    "\n",
    "for evaluator in pipeline.prediction_evaluators:  # Select all measures that are not nan.\n",
    "    meas = np.asarray(evaluator.result['accuracy_score']['measures'])\n",
    "    not_nan_idx = ~np.isnan(evaluator.result['accuracy_score']['measures'])\n",
    "    meas = meas[not_nan_idx]\n",
    "    measures.append(meas)\n",
    "\n",
    "ax = fvis.plot(measures=measures,\n",
    "               legend_labels=['Hoeffding Adaptive Tree (skmultiflow)', \n",
    "                              'Hoeffding Tree (skmultiflow)', \n",
    "                              'Logistic Regression (river)'],\n",
    "               y_label='Accuracy (%)')\n",
    "\n",
    "ax.set_xlabel('Holdout Test Iteration')  # Relabel the x-axis as the default naming is not meaningful in this case.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4011aa0-709c-4f14-8aae-90890a604c9c",
   "metadata": {},
   "source": [
    "As before, we may conclude that the Hoeffding Tree based classifiers perform better than the Logistic Regression.\n",
    "\n",
    "We can obtain a smoother plot, by showing the decayed mean and variance instead below. Other than for the raw measures shown above, the decayed mean measures do not contain nan values. That is, if the models are not tested at an iteration, the PredictionEvaluator simply does not udpate the decayed mean (this can be observed in the first plot below). The decayed mean is the only measure where such a behaviour is meaningful, as it is not affected by the number of tests involved in the averaging. In order to display the same test iterations as above, we may reuse the indices specified in the not_nan_idx variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93974e7e-94ba-4f05-91da-f35cbe3ed629",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fvis.plot(measures=[evaluator.result['accuracy_score']['mean_decay'] for evaluator in pipeline.prediction_evaluators],\n",
    "               variance_measures=[evaluator.result['accuracy_score']['var_decay'] for evaluator in pipeline.prediction_evaluators],\n",
    "               legend_labels=['Hoeffding Adaptive Tree (skmultiflow)',\n",
    "                              'Hoeffding Tree (skmultiflow)', \n",
    "                              'LogisticRegression (river)'],\n",
    "               y_label='Accuracy')\n",
    "\n",
    "plt.title('Decayed Mean over all Time Steps', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "ax = fvis.plot(measures=[np.asarray(evaluator.result['accuracy_score']['mean_decay'])[not_nan_idx] for evaluator in pipeline.prediction_evaluators],\n",
    "               variance_measures=[np.asarray(evaluator.result['accuracy_score']['var_decay'])[not_nan_idx] for evaluator in pipeline.prediction_evaluators],\n",
    "               legend_labels=['Hoeffding Adaptive Tree (skmultiflow)',\n",
    "                              'Hoeffding Tree (skmultiflow)', \n",
    "                              'LogisticRegression (river)'],\n",
    "               y_label='Accuracy')\n",
    "\n",
    "ax.set_xlabel('Holdout Test Iteration')  # Relabel the x-axis as the default naming is not meaningful in this case.\n",
    "plt.title('Decayed Mean At Actual Holdout Updates', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f652e22-872d-4089-9dd1-c70b8dd5ddc2",
   "metadata": {},
   "source": [
    "Note that global trends can often be identified more easily from an aggregated measure like the decayed mean, compared to the raw measurements shown before."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
